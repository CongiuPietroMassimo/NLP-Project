{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uso il file di train per l'addestramento, contiene 96 esempi etichettati, e dovrebbe essere bilanciato. alla label viene associata la vettorizzazione del rumor verificato.\n",
    "\n",
    "Una volta fatto questo passo alla calssificazione dei 32 rumor del devSet.\n",
    "\n",
    "Per la rumor retrieval potrei ordinare in base a quelli col contesto più forte e prendere i primi 5 che classifica come il rumor\n",
    "\n",
    "Come classificatore è stato scelto NaiveBayes per la scarsità dei dati."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apertura del file per il train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('English_train_v3.json', 'r') as f:\n",
    "    trainSet = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apertura del file dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('English_dev.json', 'r') as f:\n",
    "    devSet = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VETTORIZZAZIONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lista di tutti i rumor\n",
    "listaTrain = []\n",
    "for oggetto in trainSet:\n",
    "    listaTrain.append(oggetto[\"rumor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimTrain = len(listaTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lista di tutti i rumor\n",
    "listaTest = []\n",
    "for oggetto in devSet:\n",
    "    listaTest.append(oggetto[\"rumor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimTest = len(listaTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creazione di una lista unica da vettorizzare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "listaDaVett = listaTrain + listaTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.spatial.distance import cosine\n",
    "import heapq\n",
    "import re\n",
    "\n",
    "def vettorizzazione(rumors):\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(use_idf=True,sublinear_tf=True,smooth_idf=True, stop_words=None)\n",
    "    tfidf_matrix = vectorizer.fit_transform(rumors)\n",
    "\n",
    "    return tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "listaVett = vettorizzazione(listaDaVett)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separo le vettorizzazioni di training e di test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainVett = listaVett[:-dimTest]\n",
    "testVett = listaVett[-dimTest:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = trainVett\n",
    "\n",
    "Y = []\n",
    "for oggetto in trainSet:\n",
    "    Y.append(oggetto[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADDESTRAMENTO E CLASSIFFICAZIONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "NB = MultinomialNB()\n",
    "\n",
    "model= NB.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "listaPredictions = model.predict(testVett)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estrazione delle label dal test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = []\n",
    "for element in devSet:\n",
    "    true_labels.append(element['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcolo della Macro_F1 senza suare le loro storie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2574074074074074"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(true_labels, listaPredictions, labels=[\"SUPPORTS\", \"REFUTES\", \"NOT ENOUGH INFO\"],average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classificazione non precisa, per evidence retrieval uso i cinque tweet col contesto più forte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_list(lista):\n",
    "    ris = []\n",
    "    for elemento in lista.toarray():\n",
    "        ris.extend(elemento)\n",
    "    return ris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "import numpy\n",
    "\n",
    "listaDizionari = []\n",
    "listaDaVett = []\n",
    "\n",
    "for rumor,prediction in zip(devSet,listaPredictions):\n",
    "    #Vado a fare la vettorizzazione del rumor e della timeline\n",
    "    listaDaVett.append(rumor['rumor'])\n",
    "    for evidence in rumor['timeline']:\n",
    "        listaDaVett.append(evidence[2])\n",
    "        \n",
    "    #Vado a vettorizzare\n",
    "    listaVett = vettorizzazione(listaDaVett)\n",
    "\n",
    "    #Creo una coppia della timeline e ci aggiungo alla fine i relativi valori di coseno con il rumor\n",
    "    vettRumor = listaVett[0]\n",
    "    listaVettEvidence = listaVett[1:]\n",
    "    listaEvidence = rumor['timeline']\n",
    "    i = 0\n",
    "\n",
    "    for evidence,vettEvidence in zip(listaEvidence,listaVettEvidence):\n",
    "        evidence.append(cosine(numpy.transpose(flat_list(vettRumor)),numpy.transpose(flat_list(vettEvidence))))\n",
    "\n",
    "    #Ordino dal più basso al più alto che più è basso l'angolo e meglio è\n",
    "    listaEvidence.sort(key=lambda x: x[3])\n",
    "\n",
    "    #Prendo solo i primi 5\n",
    "    listaEvidence = listaEvidence[:5]\n",
    "\n",
    "    #Ho pronto id, label e evidence\n",
    "    dizionario = {\n",
    "            \"id\":rumor['id'],\n",
    "            \"predicted_label\":prediction,\n",
    "            \"predicted_evidence\":listaEvidence\n",
    "        }\n",
    "    listaDizionari.append(dizionario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listaDizionari"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Results/Verification/NaiveBayes_verification_results.json\", \"w\") as fr:\n",
    "    json.dump(listaDizionari, fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrivo il file di testo per le la verifica delle evidence\n",
    "with open(\"Results/Evidence/NaiveBayes_evidence_results.txt\", \"w\") as fe:\n",
    "    for rumor in listaDizionari:\n",
    "        #Scrivo le cose che servono per la verifica delle evidence\n",
    "        i = 1\n",
    "        for evid in rumor['predicted_evidence']:\n",
    "            fe.write(rumor['id']+\"\\tQ0\\t\"+evid[1]+\"\\t\"+str(i)+\"\\t\"+str(evid[3])+\"\\tIO\\n\")\n",
    "            i = i+1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
