{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MACHINE LEARNING APPROACH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This challenge is not well suited for calassic machine learning approach\n",
    "\n",
    "The larged set of labeld examples for training is the training set with 96 labeled examples\n",
    "- 38 REFUTES\n",
    "- 18 SUPPORTS\n",
    "- 40 NOT ENOUGH INFO\n",
    "The dataset is not balanced\n",
    "\n",
    "The test set is not labeled so can't be use for training or testing (results can't be verified)\n",
    "\n",
    "The dev set contains 32 labeled rumor so can be used for testing\n",
    "\n",
    "Can't supplement the traing set with dev set examples due to overfitting problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training set opening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('../Datasets/English_train_v3.json', 'r') as f:\n",
    "    trainSet = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Development set opening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Datasets/English_dev.json', 'r') as f:\n",
    "    devSet = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VECTORIZATION\n",
    "\n",
    "Training e \"Test\" sets have to be vectorized together to have the same number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training rumor list\n",
    "trainingList = []\n",
    "for rumor in trainSet:\n",
    "    trainingList.append(rumor[\"rumor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimTrain = len(trainingList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test rumor list\n",
    "testList = []\n",
    "for rumor in devSet:\n",
    "    testList.append(rumor[\"rumor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimTest = len(testList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a single list to vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "listToVectorize = trainingList + testList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "def vectorizer(rumors):\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(use_idf=True,sublinear_tf=True,smooth_idf=True, stop_words=None)\n",
    "    tfidf_matrix = vectorizer.fit_transform(rumors)\n",
    "\n",
    "    return tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizedList = vectorizer(listToVectorize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide the vectorization in training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainVett = vectorizedList[:-dimTest]\n",
    "testVett = vectorizedList[-dimTest:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = trainVett\n",
    "\n",
    "#Recovering the labels\n",
    "Y = []\n",
    "for rumor in trainSet:\n",
    "    Y.append(rumor[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLASSIFICATION\n",
    "\n",
    "The classification is done using Naive Bayes due to the scarsity of training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "NB = MultinomialNB()\n",
    "\n",
    "model= NB.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionList = model.predict(testVett)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label extraction from the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = []\n",
    "for element in devSet:\n",
    "    true_labels.append(element['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoring the Macro-F1 to have an idea ot the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2574074074074074"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(true_labels, predictionList, labels=[\"SUPPORTS\", \"REFUTES\", \"NOT ENOUGH INFO\"],average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_list(lista):\n",
    "    ris = []\n",
    "    for element in lista.toarray():\n",
    "        ris.extend(element)\n",
    "    return ris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVING RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the classification results using the format given by the challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "import numpy\n",
    "\n",
    "dictionaryList = []\n",
    "listToVectorize = []\n",
    "\n",
    "for rumor,prediction in zip(devSet,predictionList):\n",
    "    #Rumor and timeline in the same vector\n",
    "    listToVectorize.append(rumor['rumor'])\n",
    "    for evidence in rumor['timeline']:\n",
    "        listToVectorize.append(evidence[2])\n",
    "        \n",
    "    #Vectorization\n",
    "    vectorizedList = vectorizer(listToVectorize)\n",
    "\n",
    "    #Adding the cosine similarity to the timeline\n",
    "    vettRumor = vectorizedList[0]\n",
    "    vectorizedEvidence = vectorizedList[1:]\n",
    "    evidenceList = rumor['timeline']\n",
    "    i = 0\n",
    "\n",
    "    for evidence,vettEvidence in zip(evidenceList,vectorizedEvidence):\n",
    "        evidence.append(cosine(numpy.transpose(flat_list(vettRumor)),numpy.transpose(flat_list(vettEvidence))))\n",
    "\n",
    "    #Inverse sorting, the lower the better\n",
    "    evidenceList.sort(key=lambda x: x[3])\n",
    "\n",
    "    #Taking the five best scoring\n",
    "    evidenceList = evidenceList[:5]\n",
    "\n",
    "    dictionary = {\n",
    "            \"id\":rumor['id'],\n",
    "            \"predicted_label\":prediction,\n",
    "            \"predicted_evidence\":evidenceList\n",
    "        }\n",
    "    dictionaryList.append(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../Results/Verification/NaiveBayes_verification_results.json\", \"w\") as fr:\n",
    "    json.dump(dictionaryList, fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the evidence retrieval results using the format given by the challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../Results/Evidence/NaiveBayes_evidence_results.txt\", \"w\") as fe:\n",
    "    for rumor in dictionaryList:\n",
    "        i = 1\n",
    "        for evid in rumor['predicted_evidence']:\n",
    "            fe.write(rumor['id']+\"\\tQ0\\t\"+evid[1]+\"\\t\"+str(i)+\"\\t\"+str(evid[3])+\"\\tIO\\n\")\n",
    "            i = i+1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
